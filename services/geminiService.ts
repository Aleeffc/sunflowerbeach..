import { GoogleGenAI } from "@google/genai";
import { PRODUCTS } from "../constants";
import { ChatMessage } from "../types";

const apiKey = process.env.API_KEY;
const ai = apiKey ? new GoogleGenAI({ apiKey }) : null;

const SYSTEM_INSTRUCTION = `
Voc√™ √© a "Sunny", a consultora de estilo virtual da Sunflower Beach.
Sua personalidade √© alegre, sofisticada, praiana e prestativa.
O tom de voz deve ser acolhedor e elegante, similar a vendedoras de lojas de luxo como Cia Mar√≠tima ou Lenny Niemeyer.

Seu objetivo √© ajudar a cliente a escolher o melhor look para a praia, piscina ou resort.
Voc√™ tem acesso ao seguinte cat√°logo de produtos da loja (use essas informa√ß√µes para recomendar):

${PRODUCTS.map(p => `- ID: ${p.id}, Nome: ${p.name}, Categoria: ${p.category}, Pre√ßo: R$ ${p.price.toFixed(2)}, Descri√ß√£o: ${p.description}`).join('\n')}

Regras:
1. Sempre tente sugerir produtos espec√≠ficos do cat√°logo que combinem com o pedido da cliente.
2. Se a cliente perguntar sobre algo que n√£o vendemos, gentilmente redirecione para nossos produtos (ex: n√£o vendemos sapatos, mas temos chap√©us e bolsas).
3. Responda de forma concisa, mas calorosa. Use emojis de praia/sol ocasionalmente üåªüåä.
4. Se recomendar um produto, mencione o nome exato dele.
`;

export const sendMessageToGemini = async (history: ChatMessage[], userMessage: string): Promise<string> => {
  if (!ai) {
    return "Desculpe, o servi√ßo de IA n√£o est√° configurado corretamente (Chave de API ausente).";
  }

  try {
    // We use the generateContent method directly with history formatting manually for simplicity in this stateless service wrapper,
    // or we could maintain a chat session object. For a simple React app, creating a new generation with context is robust.
    
    // Convert history to string context for simplicity with single-turn optimization or use multi-turn chat structure
    // Let's use the chat model properly.
    
    const chat = ai.chats.create({
      model: 'gemini-2.5-flash',
      config: {
        systemInstruction: SYSTEM_INSTRUCTION,
        temperature: 0.7, 
      },
      history: history.map(h => ({
        role: h.role,
        parts: [{ text: h.text }]
      }))
    });

    const result = await chat.sendMessage({ message: userMessage });
    return result.text || "Desculpe, n√£o consegui pensar em uma resposta agora. Pode tentar novamente?";

  } catch (error) {
    console.error("Error talking to Gemini:", error);
    return "Ops, tive um pequeno problema t√©cnico devido √† maresia! Tente novamente em instantes.";
  }
};